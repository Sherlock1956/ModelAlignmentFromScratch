# 说明

本文件为完成cs336_assignment2的与DDP分布式训练和Sharded Optimizer相关的实现，每一个一组标题对应一个[官方作业指导说明书](./cs336_spring2025_assignment2_systems.pdf)中的一个需要自己实现的部分。每个部分的要求以及相关指导在指导书中有详细描述。如果涉及到相关代码，在每个一组标题下会单独标注在项目中的代码位置。

**举例** 以distributed_communication_single_node为例，对应说明书中P26中的图示部分，代码位置是在tests/DDP_allreduce_demo.py

![image-9](/Users/lyx/.Trash/CS336-assignment3/assets/image16.png)

## math_baseline P6

代码位置：cs336_alignment/math_baseline.py

(a)测试 Qwen 2.5 Math 1.5B zero-sho在gsm8k test数据集上的性能，从多个角度分析结果

按照官方给出的奖励模型来判断模型的回答和gt是否是同一个答案，但是模型要求严格的format，不然就自成是结果错误，并且对于除了纯数字的输出可以判断为正确，即使答案正确但是包含了其他文字，也会算做不正确。

(b)正确率为1.66%，分析出错的所有情况：
题目一共有1319个，其中format和answer都正确的有22个，format正确但是answer不正确的有252个，format和answer都不正确的有1045个

分析具体的case可以得到以下几个结论：

1. 1.5B模型的指令跟随能力不强，无法正确输出\<think\> \</think\> \<answer\> \</answer\>等格式，在这个部分中，也有一些输出其实是正确的，只是没有遵循要求的格式。
2. 有部分遵循了格式但是结果判断为错误的，其实是正确的，只是说了一句陈述句来表达结果，但是由于结果解析匹配的问题，导致判断为了不正确。
3. 虽然这样的格式要求和正确性判断无法测试出Qwen 2.5 Math 1.5B对于数学问题的真实回答水平，但是可以在后续的sft和rl中看到明显的测评结果提升，从而学习sft和rl的效果特征。

## tokenize_prompt_and_output P9

代码位置：cs336_alignment/utils.py

写一个函数将prompt和output进行tokenize并拼接，核心需要注意以下几个点

- 输入的prompt_strs和outpout_strs都是list，需要单独将每个str都tokenize然后进行统一转换成torch.tensor，padding_token只将输出部分设置为1，prompt和padding都为0，padding需要的长度由一个batch内最长的一个数据决定
- **重要**：需要注意的是需要对input_ids和labels进行截断，一个删除最后一个token，一个删除第一个，但是需要在加入padding token之后再进行截断，而不是先截断再加padding token

## compute_entropy P10

代表位置：cs336_alignment/utils.py

计算一个token output logits的分布信息熵，信息熵越小，说明模型对下一个token的预测越确定，信息熵越大，说明越不确定。token entropy的范围是0到log|X|，|X|是词表大小

计算方法如下：
$$
H(p) = -\sum_{x\in V}p(x)logp(x)
$$
其中在计算概率的时候会用到softmax来计算，因为大模型的输出只是logits并不是概率。而为了防止数值不稳定，需要使用logsumexp的技巧，也就是先减去一个最小值再计算softmax，而在torch中有一些相关的函数，比如

```python
torch.nn.functional.log_softmax()# 稳定计算一堆数据的softmax之后求对数
torch.logsumexp()# 稳定计算一堆数据的对数指数和
```

其中就可以使用log_softmax来计算公式中的logp(x)，然后再使用torch.exp()就可以得到概率
