n_grpo_steps: int = 200
learning_rate: float = 1e-6
advantage_eps: float = 1e-6
rollout_batch_size: int = 256
group_size: int = 8
sampling_temperature: float = 1.0
sampling_min_tokens: int = 4 # As in Expiter, disallow empty string responses
sampling_max_tokens: int = 1024
epochs_per_rollout_batch: int = 1 # On-policy
train_batch_size: int = 64 # On-policy
gradient_accumulation_steps: int = 64 # microbatch size is 2, will fit on H100
gpu_memory_utilization: float = 0.85
loss_type = "grpo_clip"
use_std_normalization: bool = True
lr=learning_rate
weight_decay=0.0
betas=(0.9, 0.95)
max_grad_norm=1.0
cliprange=0.05